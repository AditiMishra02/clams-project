# ğŸš€ CLAMS â€” Cloud Log Aggregation & Monitoring System  
![CI/CD Status](https://github.com/AditiMishra02/clams-project/actions/workflows/ci.yml/badge.svg)

A lightweight, production-ready **Cloud Log Ingestion & Monitoring System** designed to collect application logs and store them securely on **AWS S3**, built with:

- **Python + Flask** (Backend API)
- **Docker** (Containerization)
- **GitHub Actions** (CI/CD)
- **AWS S3** (Storage)
- **WSL2 + Ubuntu** (Local Dev Environment)

This project demonstrates **real DevOps, Cloud & Backend Engineering skills**, showing how a modern SaaS-style log collection pipeline works.

---

# ğŸ“Œ **Table of Contents**

1. [Project Overview](#-project-overview)  
2. [Architecture Diagram](#-architecture-diagram)  
3. [Tech Stack](#-tech-stack)  
4. [Features](#-features)  
5. [Folder Structure](#-folder-structure)  
6. [How to Run Locally](#-how-to-run-locally)  
7. [API Documentation](#-api-documentation)  
8. [Docker Support](#-docker-support)  
9. [CI/CD Pipeline](#-cicd-pipeline)  
10. [Log Generator](#-log-generator)  
11. [Deployment Options](#-deployment-options)  
12. [Screenshots](#-screenshots)  
13. [Future Enhancements](#-future-enhancements)  
14. [Author](#-author)

---

# ğŸš€ **Project Overview**

**CLAMS (Cloud Log Aggregation & Monitoring System)**  
is a simple but powerful backend service that receives logs from applications and stores them securely in **Amazon S3**.

It simulates real-world systems like:

- AWS CloudWatch Logs  
- Datadog Log Ingestion  
- ELK Stack Ingestion APIs  
- Splunk HTTP Event Collector  

This makes it an impressive DevOps + Cloud + Backend project for your resume.

---

# ğŸ–¼ **Architecture Diagram**

# ğŸš€ CLAMS â€” Cloud Log Aggregation & Monitoring System  
![CI/CD Status](https://github.com/AditiMishra02/clams-project/actions/workflows/ci.yml/badge.svg)

A lightweight, production-ready **Cloud Log Ingestion & Monitoring System** designed to collect application logs and store them securely on **AWS S3**, built with:

- **Python + Flask** (Backend API)
- **Docker** (Containerization)
- **GitHub Actions** (CI/CD)
- **AWS S3** (Storage)
- **WSL2 + Ubuntu** (Local Dev Environment)

This project demonstrates **real DevOps, Cloud & Backend Engineering skills**, showing how a modern SaaS-style log collection pipeline works.

---

# ğŸ“Œ **Table of Contents**

1. [Project Overview](#-project-overview)  
2. [Architecture Diagram](#-architecture-diagram)  
3. [Tech Stack](#-tech-stack)  
4. [Features](#-features)  
5. [Folder Structure](#-folder-structure)  
6. [How to Run Locally](#-how-to-run-locally)  
7. [API Documentation](#-api-documentation)  
8. [Docker Support](#-docker-support)  
9. [CI/CD Pipeline](#-cicd-pipeline)  
10. [Log Generator](#-log-generator)  
11. [Deployment Options](#-deployment-options)  
12. [Screenshots](#-screenshots)  
13. [Future Enhancements](#-future-enhancements)  
14. [Author](#-author)

---

# ğŸš€ **Project Overview**

**CLAMS (Cloud Log Aggregation & Monitoring System)**  
is a simple but powerful backend service that receives logs from applications and stores them securely in **Amazon S3**.

It simulates real-world systems like:

- AWS CloudWatch Logs  
- Datadog Log Ingestion  
- ELK Stack Ingestion APIs  
- Splunk HTTP Event Collector  

This makes it an impressive DevOps + Cloud + Backend project for your resume.

---

# ğŸ–¼ **Architecture Diagram**


            +----------------------+
            |   Frontend / Apps    |
            |  (Send Logs via API) |
            +----------+-----------+
                       |
                       | HTTP POST /upload-log
                       v
             +---------+----------+
             |   Flask API (WSL)  |
             |  /upload-log route |
             +---------+----------+
                       |
                       | boto3
                       v
             +---------+----------+
             |       AWS S3       |
             |  log-storage-bucket|
             +---------+----------+
                       |
                       v
            Logs stored securely with
            timestamps & unique IDs

---

# ğŸ›  **Tech Stack**

### **Backend**
- Python 3.10  
- Flask  
- Boto3 (AWS SDK)

### **Cloud**
- AWS S3  
- IAM Access Keys  
- Free Tier compliant

### **DevOps**
- Docker (Containerization)  
- GitHub Actions (CI/CD)  
- WSL2 Ubuntu (Local Development)

---

# â­ **Features**

âœ” Accepts logs from any app via `POST /upload-log`  
âœ” Stores logs in AWS S3 with unique timestamp file names  
âœ” Fully containerized with Docker  
âœ” GitHub Actions CI/CD pipeline  
âœ” Secure environment variable handling (no AWS keys in repo)  
âœ” Log generator for demonstration  
âœ” Works on free AWS tier  

---

# ğŸ“ **Folder Structure**

clams-project/
â”‚
â”œâ”€â”€ backend/
â”‚ â”œâ”€â”€ app.py # Flask API (main backend)
â”‚ â”œâ”€â”€ log_generator.py # Simulates real logs
â”‚ â”œâ”€â”€ requirements.txt # Python dependencies
â”‚ â””â”€â”€ Dockerfile # Backend Docker image
â”‚
â”œâ”€â”€ .github/workflows/
â”‚ â””â”€â”€ ci.yml # CI/CD pipeline
â”‚
â”œâ”€â”€ .gitignore
â””â”€â”€ README.md


---

# ğŸ§ª **How to Run Locally**

### **1ï¸âƒ£ Activate your virtual environment**

```bash
source venv/bin/activate
2ï¸âƒ£ Install dependencies
pip install -r backend/requirements.txt

3ï¸âƒ£ Run the Flask API
cd backend
python3 app.py


Runs at:

http://127.0.0.1:5000/

ğŸ“¡ API Documentation
POST /upload-log
Request

Option A â€” Raw Text Log

curl -X POST -d "User login failed" http://127.0.0.1:5000/upload-log


Option B â€” JSON Log

curl -X POST -H "Content-Type: application/json" \
     -d '{"log": "Payment failed"}' \
     http://127.0.0.1:5000/upload-log

Response
{
  "message": "Log uploaded successfully",
  "s3_path": "logs/log_2025-11-21T10-30-00.txt"
}

ğŸ³ Docker Support
Build the Docker image
docker build -t clams-backend .

Run the container
docker run -p 5000:5000 clams-backend

Run with AWS credentials
docker run -p 5000:5000 \
  -e AWS_ACCESS_KEY_ID=xxxx \
  -e AWS_SECRET_ACCESS_KEY=yyyy \
  -e AWS_DEFAULT_REGION=ap-south-1 \
  -e S3_BUCKET=clams-log-bucket \
  clams-backend

ğŸ”„ CI/CD Pipeline

This project uses GitHub Actions to:

âœ” Build Docker image
âœ” Push image to GitHub Container Registry
âœ” Run integration tests
âœ” Validate code

CI badge:

ğŸ”¥ Log Generator

Simulate real-time logs:

python3 log_generator.py


You will see:

Sent: User logged in | Status: 200
Sent: Payment failed | Status: 200
Sent: CPU usage exceeded threshold | Status: 200


logs will appear inside AWS S3 automatically.


ğŸ‘©â€ğŸ’» Author
Aditi Mishra

Aspiring DevOps + Cloud + Backend Engineer

AWS | Docker | CI/CD | Terraform | Python

GitHub: @AditiMishra02
